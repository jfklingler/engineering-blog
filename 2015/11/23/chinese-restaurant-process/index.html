<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    
        
    
    <meta property="og:site_name" content="Monsanto Engineering Blog" />
    <meta property="og:title" content="Optimized Chinese Restaurant Process" />
    <meta property="og:description" content="Bayesian methods provide a theoretically well principled way to accomplish data science tasks, even basic tasks like clustering. Using a variety of performance optimizations we were able to sufficiently reduce the IO, memory and CPU (300,000&times;!) required to run large scale clustering based on the Chinese Restaurant Process (CRP). CRP is a non-parametric generative Bayesian model of a &quot;mixture&quot; that simultaneously learns the number of clusters, the model of each cluster, and entity assignments into clusters. We have open sourced this project in Scala for use on &quot;count&quot; data." />
    <meta property="og:url" content="http://engineering.monsanto.com/2015/11/23/chinese-restaurant-process/" />
    <meta property="og:image" content="http://engineering.monsanto.com/img/mon-hands_grains.jpg" />
    <meta name="description" content="Bayesian methods provide a theoretically well principled way to accomplish data science tasks, even basic tasks like clustering. Using a variety of performance optimizations we were able to sufficiently reduce the IO, memory and CPU (300,000&times;!) required to run large scale clustering based on the Chinese Restaurant Process (CRP). CRP is a non-parametric generative Bayesian model of a &quot;mixture&quot; that simultaneously learns the number of clusters, the model of each cluster, and entity assignments into clusters. We have open sourced this project in Scala for use on &quot;count&quot; data." />
    

    <link rel="shortcut icon" href="/favicon.ico" />

    <title>Optimized Chinese Restaurant Process - Engineering at Monsanto</title>

    <link rel="canonical" href="http://engineering.monsanto.com/2015/11/23/chinese-restaurant-process/" />

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.min.css" />
    <link rel="stylesheet" href="/css/scala-colors.min.css" />

    

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css" />

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css" />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="http://engineering.monsanto.com/feed.xml">

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Engineering at Monsanto</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/code/">Code</a>
                </li>
                
                <li>
                    <a href="/contact/">Contact</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/mon-hands_grains.jpg')">
    <div class="heading-underlay">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>Optimized Chinese Restaurant Process</h1>
                        
                        <h2 class="subheading">or Clustering with the Dirichlet Process Mixture Model in Scala</h2>
                        
                        <span class="meta">Posted  by Ryan Richt on November 23, 2015</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 post-body">

				<h2>TL;DR</h2>

<p>Bayesian methods provide a theoretically well principled way to accomplish data science tasks, even basic tasks like clustering. Using a variety of performance optimizations we were able to sufficiently reduce the IO, memory and CPU (300,000&times;!) required to run large scale clustering based on the Chinese Restaurant Process (CRP). CRP is a non-parametric generative Bayesian model of a &ldquo;mixture&rdquo; that simultaneously learns the number of clusters, the model of each cluster, and entity assignments into clusters. We have <a href="https://github.com/MonsantoCo/chinese-restaurant-process">open sourced</a> this project in Scala for use on &ldquo;count&rdquo; data.</p>

<p>And you can run this sucker with:</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">com.monsanto.labs.tribes._</span>
<span class="k">import</span> <span class="nn">com.monsanto.labs.tribes.clustering._</span>

<span class="k">val</span> <span class="n">cannedAllTopicVectorResults</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">[</span><span class="kt">TopicVectorInput</span><span class="o">]</span> <span class="k">=</span> <span class="nc">MnMGen</span><span class="o">.</span><span class="n">cannedData</span>
<span class="k">val</span> <span class="n">cannedCrp</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CRP</span><span class="o">(</span><span class="nc">ModelParams</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="n">cannedAllTopicVectorResults</span><span class="o">)</span>
<span class="k">val</span> <span class="n">crpResult</span> <span class="k">=</span> <span class="n">cannedCrp</span><span class="o">.</span><span class="n">findClusters</span><span class="o">(</span><span class="mi">200</span><span class="o">,</span> <span class="nc">RealRandomNumGen</span><span class="o">,</span> <span class="n">cannedCrp</span><span class="o">.</span><span class="n">selectCluster</span><span class="o">)</span>
</code></pre></div>
<blockquote>
<p>Iteration 1: cluster count was 365, reseat: 35, score: -29578.83920*<br>
Iteration 2: cluster count was 118, reseat: 15, score: -29111.34349*<br>
Iteration 3: cluster count was 61, reseat: 7, score: -28919.62995*<br>
Iteration 4: cluster count was 40, reseat: 6, score: -28852.91482*<br>
Iteration 5: cluster count was 29, reseat: 6, score: -28804.38123*<br>
Iteration 6: cluster count was 24, reseat: 5, score: -28741.68993*<br>
Iteration 7: cluster count was 16, reseat: 5, score: -28734.04974*<br>
Iteration 8: cluster count was 14, reseat: 6, score: -28742.16624<br>
Iteration 9: cluster count was 12, reseat: 5, score: -28739.19560<br>
Iteration 10: cluster count was 10, reseat: 5, score: -28738.64498<br>
&hellip;<br>
Iteration 190: cluster count was 4, reseat: 10, score: -28724.77273<br>
Iteration 191: cluster count was 3, reseat: 11, score: -28724.77273<br>
Iteration 192: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 193: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 194: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 195: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 196: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 197: cluster count was 3, reseat: 11, score: -28724.77273<br>
Iteration 198: cluster count was 3, reseat: 10, score: -28724.77273<br>
Iteration 199: cluster count was 3, reseat: 13, score: -28724.77273<br>
Iteration 200: cluster count was 3, reseat: 12, score: -28724.77273</p>
</blockquote>

<h2>Because who really knows what &ldquo;K&rdquo; should be anyway?</h2>

<p>At Monsanto we have a variety of analytics and data science groups working on everything from sales transactions to aerial and satellite imaging to genome (DNA) sequencing. One of the oldest and most common data science problems is clustering: given a set of objects with possibly many properties, what is an appropriate partition of those entities into groups? Below we&rsquo;ll first describe the statistical method we used to perform clustering and then the software optimizations we implemented to make this scale. </p>

<h3>Generative Bayesian Models</h3>

<p>In Monsanto Labs, we are Bayesians, and as the late <a href="http://bayes.wustl.edu">E.T. Jaynes</a> espoused, we don&rsquo;t believe in &ldquo;ad hockeries&rdquo; like K-means (a numerical method) or ad hoc &ldquo;machine learning&rdquo; techniques such as random forests. Instead we have a better way: using only the laws of probability theory. Clustering is actually a difficult problem to cast in the Bayesian paradigm, but new theoretical results and the rise of computing power over the past few decades have made this problem tractable. </p>

<p>Proper Bayesian models are &ldquo;generative,&rdquo; meaning that they posit an underlying (or latent) &ldquo;generating&rdquo; process that creates the data we see. It is precisely writing a computer program to recreate the observed data, perhaps with some input variables missing that we want to recover. <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov-chain Monte Carlo (MCMC)</a> then provides a universal mechanism to &ldquo;invert&rdquo; or solve for those input variables for such programs given some data. In the simplest case, say we observe the heights of a room of N people. The generating function could be, a normal distribution with some mean and variance that we draw N samples from. MCMC could then be run on those samples to try to recover the most likely parameters of that normal distribution.</p>

<p>We can also construct more complex generating functions (and still solve them with MCMC). Perhaps a better generating function would be to draw Male vs Female from a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a> (probability of being female in the population, like a weighted coin toss), and conditional on the result, draw a height from either the male-specific or female-specific height distribution.</p>

<h3>Bayesian Clustering</h3>

<p>Mixture models are a Bayesian way of clustering: your generating function produces a mixed population of entities from an underlying discrete set of components. For instance, imagine I give you a stream of unlabeled bags of M&amp;M&rsquo;s&#8482;<sup><a href="#mm">&dagger;</a></sup> candies. All you get to observe is a few colored M&amp;Ms™ of each bag. This is <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial</a> count data: we have a finite discrete &ldquo;vocabulary&rdquo; of colors and we will observe some number of counts of each color.</p>

<p>A multinomial distribution is just like a weighted (unfair) many-sided die, with one side for each outcome. For Christmas M&amp;M&#39;s™ say we have a 3-sided die with faces indicating {Red, Green White} which lands on Red 40% of the time, Green 40% of the time and White 20% of the time. To generate a draw of size M (say, 35 candies) from this multinomial you just roll this die M times and count up a vector of each possible color.</p>

<p><img src="/img/MnMs_Clustering.png" alt="clustering colored candies"></p>

<p>Imagine that the generating function is first buying a bag on a random day. Most of the year you can get bags with classic colors, for 2 weeks you can get Christmas colors, and for 3 days you can get 4th of July colors. So from this distribution of K types of bags say we draw N bags. Then we erase the packaging label of each, and I give you a handful of candies from each bag. Note that there is significant overlap in the colors from each kind of bag. From a small handful of say, Christmas M&amp;M&#39;s™ where you didn&rsquo;t chance to draw and white colored candies, its hard to say if you they are Christmas or plain! From only these handfuls, your clustering job is to tell me:</p>

<ol>
<li>How many kinds of bags there are</li>
<li>A model of the data produced from each kind of bag</li>
<li>Which handfuls came from which kinds of bags</li>
</ol>

<p>So this is a clustering process. It is mixture of types of bags, and since we don&rsquo;t get the see the labels of the bags we have a mixture model. The unknown kinds of bags are the clusters, and the handfuls are our data. The multinomial counts of colors from the handfuls are our features extracted from the data, and we describe each type of bag by an explicit probability model which is a multinomial distribution.</p>

<p>Contrast this to say, K-means clustering:</p>

<table><thead>
<tr>
<th>Attribute</th>
<th>K-means</th>
<th>Bayesian Mixture Model</th>
</tr>
</thead><tbody>
<tr>
<td>Count of clusters</td>
<td>Ad hoc - user specified &ldquo;K&rdquo;</td>
<td>Probabilistic model</td>
</tr>
<tr>
<td>Membership Measure</td>
<td>Ad hoc - euclidean &ldquo;distance&rdquo;</td>
<td>Probabilistic model</td>
</tr>
<tr>
<td>Solution Method</td>
<td>Ad hoc - EM*-style iterations</td>
<td>Markov-chain Monte Carlo</td>
</tr>
<tr>
<td>Confidence Measure</td>
<td>None</td>
<td>Probabilities for all aspects</td>
</tr>
</tbody></table>

<p>(*EM or <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Expectation Maximization</a> is only guaranteed to converge to <em>local</em> optima)</p>

<p>While K-means may work OK in some cases, it leaves much to be desired.</p>

<h3>The Chinese Restaurant Process</h3>

<p>OK so we can describe a type of bag by a multinomial distribution. From several multinomials we can use <a href="https://en.wikipedia.org/wiki/Bayes%27_rule">Bayes&rsquo; Rule</a> to compute the relative probability that any given handful of candies belongs to each of the possible kinds of bags. But how do we posit kinds of bags in the first place? And how many might there be? The answer, and the probabilistic model for &ldquo;choosing K&rdquo; is the &ldquo;Chinese Restaurant Process.&rdquo; The Chinese Restaurant Process is a generating function for a mixture model, and the story goes like this: </p>

<p><img src="/img/Chinese_Restaurant_Setup.png" alt="Chinese Restaurant Process"></p>

<p>There is a large family-style Chinese restaurant with a seemingly infinite number of infinitely large tables. A line of customers come in, and they join an existing table with probability proportional to how many others are already seated there (so popular tables get more popular), and with some probability they nucleate their own <em>new</em> table. Every diner at the same table eats from the same dish, which is a common probability distribution. Their &ldquo;bites&rdquo; of the dish are our observed data points. So this is a generating function for a (clustering) mixture model, where we don&rsquo;t have to know K in advance and K can be unbounded!</p>

<p>The real beauty is that CRP properly probabilistically trades off between more &ldquo;tighter&rdquo; clusters and fewer more heterogenous clusters. Setting the &ldquo;alpha&rdquo; parameter determines the exchange rate of this trade-off, it doesn&rsquo;t specify K. You can think of the MCMC solver as running this generating function many times and looking for the highest probability assignments - where diners with similar &ldquo;bites&rdquo; are indeed assigned to the same table with the same dish, and we properly trade off the number of tables/dishes with how will the table-mates fit each dish. But instead we use a more efficient sort-of stochastic search that spends more time poking around high-probability regions but can still escape local maxima.</p>

<p>The precise low-down on the collapsed Gibbs sampler can best found <a href="http://www.clsp.jhu.edu/%7Eajansen/miniws/Johnson11MLSS-talk-extras.pdf">here</a>.</p>

<h2>The Optimization</h2>

<p>We didn&rsquo;t set out to build our own implementation. Actually there is a great <a href="http://blog.datumbox.com/the-dirichlet-process-the-chinese-restaurant-process-and-other-representations/">series of DPMM/CRP/Clustering blog posts</a> from the guys over at DatumBox, and that&rsquo;s where we stared. Open Source FTW!</p>

<p>Unfortunately we generated a large test data set with 100,000 &ldquo;bags&rdquo; each with Normal(400,100) &ldquo;candies&rdquo; sampled from 10,000 &ldquo;colors&rdquo; across 10 types of bags (clusters) with exponentially distributed membership, an Exponential(1/10) number of colors per type, and Exponential(1/100) weights of each color. Unfortunately, EXPLOSION!! And this explosion was reproducible on AWS on a behemoth memory optimized r3.8xlarge instance with a java heap size of 150GB!</p>

<p>Then we set out on what is a pretty archetypal optimization journey, but if you haven&rsquo;t done a lot of optimization, it may be of interest.</p>

<h3>Solve a Different Problem</h3>

<p>It should also be noted that, we could have subsampled our data, implemented an approximation algorithm, or as we did do, solve another problem completely. MCMC is great for samples but according to <a href="http://www.umiacs.umd.edu/%7Ehal/docs/daume07astar-dp.pdf">Daume 2007, <em>Fast search for Dirichlet process mixture models</em></a>, it doesn&rsquo;t seem to be the most efficient search strategy if you only want the single most likely clustering. So (after we were unable to make the original Matlab work) we also reimplemented Daume 2007, which is a variant of A* search with some heuristics for this problem. Turns out even with substantial optimization, and a large beam (look back) size, we always got slower, worse clusterings than with our optimized Gibbs sampler. So it seemed the original problem was indeed the one worth solving.</p>

<h3>Memory and IO</h3>

<p>The first thing we noticed was that the in-memory size of the data set was unnecessarily large. To keep Arrays of counts (aka, dense vectors) across 10,000 colors with Exponential(1/10) active colors meant that almost all of the data was zeros. While we love and make heavy use of <a href="https://github.com/scalanlp/breeze">Breeze</a> we started out with the simplest thing that could possible work for a &ldquo;sparse vector&rdquo;: a Map[Int, Int] from color index to count, filled in only for non-zero counts. This would require significant changes to the DatumBox code so we started over in Scala and implemented the collapsed Gibbs sampler for CRP with Dirichlet-Multinomial data in the <a href="http://www.clsp.jhu.edu/%7Eajansen/miniws/Johnson11MLSS-talk-extras.pdf">standard manner</a>.</p>

<p>This reduced our memory requirements from at least 150GB down to 2.2GB (68&times; RAM reduction), and improved startup time since we now needed only to parse in 6MB of data instead of 2000MB (~333&times; IO reduction).</p>

<p><img src="/img/CRP_memory_IO_reduction.png" alt="memory and IO reduction"></p>

<h3>The CPU Saga</h3>

<p>We were then very exciting to be able to run the Gibbs sampler in reasonable memory. Unfortunately we immediately hit the next problem: a single &ldquo;reseating&rdquo; of customers in the restaurant took 32.5 seconds. 32.5 seconds &times; 100,000 customers &times; 10,000 iterations = <em>1000 CPU years</em>. Ouch.</p>

<p><img src="/img/CRP_cpu_time_reduction.png" alt="CRP_cpu_time_reduction.png"></p>

<p>Using a combination of the sampler and profiler in <a href="https://visualvm.java.net/gettingstarted.html">VisualVM</a>, manual timings, and micro-benchmarks we crafted a series of 7 versions that drove the reseating time down to 0.0001 seconds. Here are some of the highlights:</p>

<h4>Initialization</h4>

<p>If you read papers on CRP, you can see that there are numerous initialization strategies: 1 object per table, log N tables with random assignments, using <em>Daume 2007</em> output as initialization, etc. While 1 object per table seems like the least likely to be biased based on random early decisions, it is also the slowest. We settled on random tables of 100 entities which gave us another 5&times; speed up or so, without detectable bias for our data.</p>

<h4>Mutability</h4>

<p>Of course we implemented the first version in the idiomatic, purely immutable Scala style, which involves a good deal of data structure copying. We first went whole hog changing everything to mutation and mutable data structures and indeed saw a ~10&times; speedup. Interestingly, it later turned out that we really only need to make a few data structures mutable (like <a href="https://github.com/MonsantoCo/chinese-restaurant-process/blob/db5cbc0e11a845e6b6add005ad10f93360478d71/src/main/scala/com/monsanto/labs/tribes/clustering/CRP.scala#L287">this one</a>) and that they could be private to their respective methods or classes. As an example we used to have clusters/tables have a sequence of all of their members, and upon reseating a person we&rsquo;d need to make a new cluster that was a copy of the old one with the new person. Instead it turned out to be much faster to both make that mutable and invert the order: members now have a mutable <code>Option[Cluster]</code> to which they currently belong and the cluster statistics are mutated upon add/remove. That&rsquo;s about a 5&times; speed up.</p>

<p><img src="/img/add_remove_occupant_slow.png" alt="add/remove occupant slow, refactor to mutable"> </p>

<p>So the overall structure is something we call &ldquo;immutable on the outside, mutable on the inside.&rdquo; Eventually we rewrote the codebase back to an immutable Scala style with only these few <em>private</em> mutable arrays for performance. </p>

<p>This is a great example of a classic lesson: there is usually only 1 hot path through the code. 90% of your code can remain pretty, idiomatic and immutable; only a small section needs to be uglified with optimization.</p>

<h4>Caching</h4>

<p>The collapsed Gibbs sampler for CRP has a central, tight, numerics heavy loop:</p>

<p><img src="/img/slow_estimate_c.png" alt="slow estimate C function"></p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="cm">/*</span>
<span class="cm"> * C is just the result of this integral. C tells you the probability</span>
<span class="cm"> * that someone is going to sit somewhere and the probability of your</span>
<span class="cm"> * uncertainty about what the parameters of that table truly are. If you</span>
<span class="cm"> * toss 10 coins and get 6 heads 4 tails, you&#39;d guess it is 60/40, but</span>
<span class="cm"> * you wouldn&#39;t be very certain. If you had 1000 samples you&#39;d be more</span>
<span class="cm"> * certain, and likely be closer to 50/50. C it is accounting for that</span>
<span class="cm"> * uncertainty.</span>
<span class="cm"> */</span>
<span class="k">def</span> <span class="n">estimateCSmoothingFirst</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="o">{</span>

  <span class="c1">// Compute partSumAi and partSumLogGammaAi by iterating through all</span>
  <span class="c1">// values in the WeightedVector&#39;s vecMap and computing the sum of the</span>
  <span class="c1">// values and their logGammas.</span>
  <span class="c1">// icky vars for performance in this critical path</span>
  <span class="k">var</span> <span class="n">partSumAi</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">var</span> <span class="n">partSumLogGammaAi</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">var</span> <span class="n">idx</span> <span class="k">=</span> <span class="mi">1</span>
  <span class="k">val</span> <span class="n">len</span> <span class="k">=</span> <span class="n">size</span> <span class="o">*</span> <span class="mi">2</span>
  <span class="k">while</span> <span class="o">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">len</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">v</span> <span class="k">=</span> <span class="n">pairs</span><span class="o">(</span><span class="n">idx</span><span class="o">)</span>
    <span class="n">partSumAi</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">beta</span> <span class="c1">// add beta to this and the next value to smooth the curve</span>
    <span class="k">val</span> <span class="n">logGammaSmoothingFirst</span> <span class="k">=</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">v</span> <span class="o">&lt;</span> <span class="n">allTopicVectorResults</span><span class="o">.</span><span class="n">length</span><span class="o">)</span> <span class="n">cache</span><span class="o">(</span><span class="n">v</span><span class="o">)</span>
      <span class="k">else</span> <span class="n">logGamma</span><span class="o">(</span><span class="n">v</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">beta</span><span class="o">)</span>
    <span class="n">partSumLogGammaAi</span> <span class="o">+=</span> <span class="n">logGammaSmoothingFirst</span>
    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">2</span>
  <span class="o">}</span>
</code></pre></div>
<p>And that logGamma special function, even given a numerical approximation expansion is pretty slow given all its instructions:</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// Gamma is the continuous version of factorial, but off by 1, and its</span>
<span class="c1">// more accurate to compute it and its log in one step</span>
<span class="k">def</span> <span class="n">logGamma</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">tmp</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="o">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">)</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">4.5</span><span class="o">)</span> <span class="o">-</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">4.5</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">ser</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">76.18009173</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">0</span><span class="o">)</span> <span class="o">-</span> <span class="mf">86.50532033</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">+</span>
    <span class="mf">24.01409822</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span><span class="o">)</span> <span class="o">-</span> <span class="mf">1.231739516</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">3</span><span class="o">)</span> <span class="o">+</span>
    <span class="mf">0.00120858003</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">4</span><span class="o">)</span> <span class="o">-</span> <span class="mf">0.00000536382</span> <span class="o">/</span> <span class="o">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">)</span>
  <span class="n">tmp</span> <span class="o">+</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="n">ser</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="nc">PI</span><span class="o">))</span>
<span class="o">}</span>
</code></pre></div>
<p>Turns out for our data set, this special function would literally be called <em>1 trillion times!</em></p>

<p>In the naive implementation, we actually call logGamma on a <code>Double</code>. But that <code>Double</code> is really the value of the sum of some counts (an <code>Int</code>) and a prior probability term that certainly needs to be a <code>Double</code> because we often want values &lt;1. So we pulled a couple of tricks:</p>

<ul>
<li>The value of that prior <code>Double</code> is constant for the whole run, its not unknown, so what if we just add it <em>inside</em> a caching function? Now its a function of an <code>Int</code>.</li>
<li>This is a function of positive <code>Int</code>&rsquo;s over count data. So if we can assume some bounded size, there are a very small number of possible output values. Even if we allow the range 0-1,000,000 of input values, that&rsquo;s a tiny amount of memory and computes the function 1,000,000 times fewer! In fact we can just call the slow version if we&rsquo;re outside that range with a low-overhead if-check.</li>
<li>We can even do better than using a <code>Map[Int, Double]</code>, since this is a function of Int (plus that double we add inside the function) we can just do direct lookups in an <code>Array</code> indexed by the argument.</li>
<li>Turns out its a lot of conditional logic and possible cache-blowing to check and fill in the map dynamically, we can just pre-fill the whole thing very fast on program startup. </li>
</ul>

<p>There&rsquo;s another 10&times;.</p>

<h4>Boxing</h4>

<p>The code has a number of <code>Map</code>&rsquo;s and <code>Seq</code>&rsquo;s of <code>Int</code>&rsquo;s and <code>Double</code>&rsquo;s which while normally innocuous once you get down to extreme optimization really start to add up with occasional un/boxing overhead. We fell in love with the open source library <a href="https://github.com/non/debox">Debox</a> by Scala math genius Erik Asheim <a href="https://twitter.com/d6">@d6</a> and recommend it highly. Subbing in these specialized data structures gave us another 5&times; speedup while keeping our code clean.</p>

<h4>Micro-benchmarks: Fastest Map Combiner?</h4>

<p>At some point the slowest part of the code was then computing the updated statistics for each table. These stats operate over the a (sparse) vector of counts summed across all diners sitting at this table. We have our now <code>Debox.Map</code> based sparse vectors, so what is the fastest way to sum a collection over them? Hint: its not &ldquo;just the Monoid over addition!&rdquo;</p>

<p>First we made a series of alternatives and timed this. Which do you think would be faster, or why are they not all the same?</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">first</span> <span class="k">=</span> <span class="nc">Range</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">30</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="mi">17</span><span class="o">)).</span><span class="n">toMap</span>
<span class="k">val</span> <span class="n">second</span> <span class="k">=</span> <span class="nc">Range</span><span class="o">(</span><span class="mi">15</span><span class="o">,</span><span class="mi">44</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">i</span> <span class="o">-&gt;</span> <span class="mf">64.0</span><span class="o">)).</span><span class="n">toMap</span>

<span class="k">def</span> <span class="n">v1</span><span class="o">()</span> <span class="k">=</span> <span class="o">{</span>
  <span class="c1">// Add tv&#39;s vecMap to smoothedCounts vecMap. // MAKE THIS SIMPLER</span>
  <span class="k">val</span> <span class="n">temp</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]</span> <span class="k">=</span> <span class="n">first</span><span class="o">.</span><span class="n">toVector</span><span class="o">.</span><span class="n">map</span><span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">j</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">j</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>
  <span class="o">}</span> <span class="o">++</span> <span class="n">second</span><span class="o">.</span><span class="n">toVector</span>
  <span class="k">val</span> <span class="n">temp2</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Vector</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">)]]</span> <span class="k">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">temp3</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Vector</span><span class="o">[</span><span class="kt">Double</span><span class="o">]]</span> <span class="k">=</span> <span class="n">temp2</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="n">xs</span> <span class="k">=&gt;</span> <span class="n">xs</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">))</span>
  <span class="k">val</span> <span class="n">topicCountsSums</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">temp3</span><span class="o">.</span><span class="n">mapValues</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>
  <span class="n">topicCountsSums</span><span class="o">.</span><span class="n">head</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">v2</span><span class="o">()</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">allDenseKeys</span> <span class="k">=</span> <span class="n">first</span><span class="o">.</span><span class="n">keySet</span> <span class="o">++</span> <span class="n">second</span><span class="o">.</span><span class="n">keySet</span>
  <span class="k">val</span> <span class="n">diffs</span> <span class="k">=</span> <span class="n">allDenseKeys</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">index</span> <span class="k">=&gt;</span>
    <span class="n">index</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="n">first</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">index</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span> <span class="o">+</span> <span class="n">second</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">index</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
  <span class="o">}.</span><span class="n">toMap</span>
  <span class="n">diffs</span><span class="o">.</span><span class="n">head</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">v3</span><span class="o">()</span> <span class="k">=</span> <span class="o">{</span>

  <span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">Map</span><span class="o">.</span><span class="n">empty</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">]</span>
  <span class="n">first</span><span class="o">.</span><span class="n">keySet</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span> <span class="n">k</span> <span class="k">=&gt;</span> <span class="n">sums</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">first</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="o">)</span>
  <span class="n">second</span><span class="o">.</span><span class="n">keySet</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span> <span class="n">k</span> <span class="k">=&gt;</span> <span class="n">sums</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">second</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="o">)</span>
  <span class="n">sums</span><span class="o">.</span><span class="n">head</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">v4</span><span class="o">()</span> <span class="k">=</span> <span class="o">{</span>

  <span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">Map</span><span class="o">.</span><span class="n">empty</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">]</span>
  <span class="n">first</span><span class="o">.</span><span class="n">foreach</span><span class="o">{</span> <span class="n">kv</span> <span class="k">=&gt;</span> <span class="n">sums</span><span class="o">(</span><span class="n">kv</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">kv</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">kv</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  <span class="n">second</span><span class="o">.</span><span class="n">foreach</span><span class="o">{</span> <span class="n">kv</span> <span class="k">=&gt;</span> <span class="n">sums</span><span class="o">(</span><span class="n">kv</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">kv</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">kv</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  <span class="n">sums</span><span class="o">.</span><span class="n">head</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">v5</span><span class="o">()</span> <span class="k">=</span> <span class="o">{</span>

  <span class="k">val</span> <span class="n">sums</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">Map</span><span class="o">.</span><span class="n">empty</span><span class="o">[</span><span class="kt">Int</span>, <span class="kt">Double</span><span class="o">]</span>
  <span class="n">first</span><span class="o">.</span><span class="n">foreach</span><span class="o">{</span> <span class="n">kv</span> <span class="k">=&gt;</span> <span class="k">val</span> <span class="n">k</span> <span class="k">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">_1</span> <span class="o">;</span> <span class="n">sums</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">kv</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  <span class="n">second</span><span class="o">.</span><span class="n">foreach</span><span class="o">{</span> <span class="n">kv</span> <span class="k">=&gt;</span> <span class="k">val</span> <span class="n">k</span> <span class="k">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">_1</span> <span class="o">;</span> <span class="n">sums</span><span class="o">(</span><span class="n">k</span><span class="o">)</span> <span class="k">=</span> <span class="n">sums</span><span class="o">.</span><span class="n">getOrElse</span><span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span> <span class="o">+</span> <span class="n">kv</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  <span class="n">sums</span><span class="o">.</span><span class="n">head</span>
<span class="o">}</span>
</code></pre></div>
<p>It turns out that after warmup, v1 is 2&times; as fast as v2, v3 is 2&times; as fast as v1, v4 is yet faster (but v5 is not). Who would have thought such big differences here!</p>

<p>Turns out, this is <em>still</em> not the fastest way to do it. The slowest part comes in iterating over the lists twice because we need to compute the set of all the keys, or having to do the more expensive <code>getOrElse</code> calls. What if we could do everything in one pass? We settled on a class that implements are final version which makes use of the following facts:</p>

<ul>
<li>Our keys and values are both <code>Int</code>&rsquo;s so we can keep them in one specialized <code>Array</code> as key1, value1, key2, value2, &hellip; pairs to avoid lookups</li>
<li>Even though its asymptotically more work, it&rsquo;s actually pretty low cost to keep the &ldquo;maps&rdquo; as <em>sorted</em> lists of key value pairs (recall that say, hash tables have all O(1) operations and don&rsquo;t have to do any sorting)</li>
<li>We can then <em>simultaneously</em> iterate through both lists of key/value pairs and build up the summed sparse vector in one pass. If we are at the same key in both lists we can output their sum, if we are ahead on one side we know we can output the lower side to the output vector, and we can consume at different rates to ensure we&rsquo;re always in sync.</li>
</ul>

<p>That looks about like this:</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// Array(key0, value0, key1, value1, key2, value2, ...</span>
<span class="c1">// plus possibly some unused elements at the end)</span>
<span class="k">final</span> <span class="k">class</span> <span class="nc">VecMap</span> <span class="k">private</span> <span class="o">(</span><span class="k">private</span> <span class="k">val</span> <span class="n">pairs</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">],</span> <span class="k">val</span> <span class="n">size</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>

  <span class="k">def</span> <span class="o">+(</span><span class="n">that</span><span class="k">:</span> <span class="kt">VecMap</span><span class="o">)</span><span class="k">:</span> <span class="kt">VecMap</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">thisLen</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="mi">2</span> <span class="c1">// Length of used portion of this.pairs array</span>
    <span class="k">val</span> <span class="n">thatLen</span> <span class="k">=</span> <span class="n">that</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="mi">2</span> <span class="c1">// Length of used portion of that.pairs array</span>
    <span class="k">val</span> <span class="n">newPairs</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">](</span><span class="n">thisLen</span> <span class="o">+</span> <span class="n">thatLen</span><span class="o">)</span>
    <span class="k">var</span> <span class="n">thisIdx</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="k">var</span> <span class="n">thatIdx</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="k">var</span> <span class="n">newIdx</span> <span class="k">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">thisIdx</span> <span class="o">&lt;</span> <span class="n">thisLen</span> <span class="o">&amp;&amp;</span> <span class="n">thatIdx</span> <span class="o">&lt;</span> <span class="n">thatLen</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">thisKey</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thisIdx</span><span class="o">)</span>
      <span class="k">val</span> <span class="n">thatKey</span> <span class="k">=</span> <span class="n">that</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thatIdx</span><span class="o">)</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">thisKey</span> <span class="o">==</span> <span class="n">thatKey</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span><span class="o">)</span> <span class="k">=</span> <span class="n">thisKey</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thisIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="n">that</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thatIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
        <span class="n">thisIdx</span> <span class="o">+=</span> <span class="mi">2</span>
        <span class="n">thatIdx</span> <span class="o">+=</span> <span class="mi">2</span>
      <span class="o">}</span>
      <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">thisKey</span> <span class="o">&lt;</span> <span class="n">thatKey</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span><span class="o">)</span> <span class="k">=</span> <span class="n">thisKey</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thisIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
        <span class="n">thisIdx</span> <span class="o">+=</span> <span class="mi">2</span>
      <span class="o">}</span>
      <span class="k">else</span> <span class="o">{</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span><span class="o">)</span> <span class="k">=</span> <span class="n">thatKey</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="n">that</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thatIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
        <span class="n">thatIdx</span> <span class="o">+=</span> <span class="mi">2</span>
      <span class="o">}</span>
      <span class="n">newIdx</span> <span class="o">+=</span> <span class="mi">2</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">thisIdx</span> <span class="o">&lt;</span> <span class="n">thisLen</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// that.pairs is spent. Just finish off this</span>
      <span class="k">while</span> <span class="o">(</span><span class="n">thisIdx</span> <span class="o">&lt;</span> <span class="n">thisLen</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span><span class="o">)</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thisIdx</span><span class="o">)</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thisIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
        <span class="n">thisIdx</span> <span class="o">+=</span> <span class="mi">2</span>
        <span class="n">newIdx</span> <span class="o">+=</span> <span class="mi">2</span>
      <span class="o">}</span>
    <span class="o">}</span>
    <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="n">thatIdx</span> <span class="o">&lt;</span> <span class="n">thatLen</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// this.pairs is spent. Just finish off that</span>
      <span class="k">while</span> <span class="o">(</span><span class="n">thatIdx</span> <span class="o">&lt;</span> <span class="n">thatLen</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span><span class="o">)</span> <span class="k">=</span> <span class="n">that</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thatIdx</span><span class="o">)</span>
        <span class="n">newPairs</span><span class="o">(</span><span class="n">newIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="n">that</span><span class="o">.</span><span class="n">pairs</span><span class="o">(</span><span class="n">thatIdx</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
        <span class="n">thatIdx</span> <span class="o">+=</span> <span class="mi">2</span>
        <span class="n">newIdx</span> <span class="o">+=</span> <span class="mi">2</span>
      <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">assert</span><span class="o">((</span><span class="n">newIdx</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="o">)</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span>
    <span class="k">new</span> <span class="nc">VecMap</span><span class="o">(</span><span class="n">newPairs</span><span class="o">,</span> <span class="n">newIdx</span> <span class="o">/</span> <span class="mi">2</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="o">...</span>
 <span class="o">}</span>
</code></pre></div>
<h4>Parallelization</h4>

<p>Finally, of course this is Scala and we have very simple access to <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections</a>. Interestingly here, Gibbs sampling is fundamentally sequential, but there are some opportunities for parallelism but several introductions of parallelism actually made CRP run slower! Always measure. But with the right use of parallel collections, such as computing the probabilities that a diner belongs to every possible existing table, we did get another 5&times; performance bump.</p>

<h2>Closing</h2>

<p>We don&rsquo;t have the time to talk about every aspect of the couple weeks we spent squeezing a 300,000&times; speed improvement out of our naive CRP clustering implementation, but we hope some of the tools and strategies above might be useful in your work. At any rate, we hope you can make use of our JVM CRP implementation, which we believe to be the only JVM implementation available for large data sets, a foundational data science tool for clustering that we&rsquo;ve now donated to the open source community.</p>

<div style="font-size: 80%;">
<a name="mm"><sup>&dagger;</sup></a>M&M&rsquo;s&#8482; is a trademark of Mars, Inc used here for illustrative educational purposes.
</div>

<p></p>


                

                        <div class="post-signature multiple">
                            posted on November 23, 2015 by <br>
                        


                            <div class="author">
                                
                                <img src="https://avatars2.githubusercontent.com/u/541228?v=3&s=40">
                                
                                    <span>
                                        Ryan Richt
                                    </span>

                                
                                <a  href="https://twitter.com/ryan_richt">
                                    <i class="fa fa-twitter fa-1x "></i>
                                </a>
                                
                                
                                <a  href="https://github.com/ryan-richt">
                                    <i class="fa fa-github fa-1x"></i>
                                </a>
                                
                            </div>
                        
                        </div>
                

                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2015/11/16/what-makes-a-data-scientist-part-3/" data-toggle="tooltip" data-placement="top" title="What Makes a Data Scientist - Part 3">&larr; Previous Post</a>
                    </li>
                    
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    <li>
                        <a href="https://twitter.com/MonPlatformEng">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.youtube.com/MonsantoCo">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-youtube-square fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.facebook.com/MonsantoCo">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/MonsantoCo">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                </ul>
                <p class="copyright text-muted">Copyright &copy; 2015 Engineering at Monsanto &nbsp;|&nbsp; Built with <a href="http://jekyllrb.com/">Jekyll</a> and hosted on <a href="https://pages.github.com/">GitHub Pages</a><br />
                    <a href="/sitemap.xml">Sitemap</a> &nbsp;|&nbsp;
                    <a href="http://www.monsanto.com/legal-notice/Pages/default.aspx">Legal Notice</a> &nbsp;|&nbsp;
                    <a href="http://www.monsanto.com/privacy-policy/Pages/default.aspx">Privacy Policy</a> &nbsp;|&nbsp;
                    <a href="/contact">Contact Us</a>

                    </p>
                <div align="center"><br /><img src="/img/Monsanto_logo.jpg" width="170" height="54" border="0" /></div>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>

<!-- Google Analytics JavaScript -->

<script>
if (/monsanto\.com/.test(window.location.hostname)) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-43186905-16', 'auto');
    ga('require', 'displayfeatures');
    ga('send', 'pageview');

    var trackOutboundLink = function(url) {
        ga('send', 'event', 'outbound', 'click', url, {'hitCallback':
                function () {
                    document.location = url;
                }
        });
    }
}
</script>
<script src="/js/main.js"></script>


</body>

</html>
